{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from io import StringIO\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_weather_from_url(df):\n",
    "    col=['STATION','DATE','HourlyAltimeterSetting','HourlyDewPointTemperature','HourlyDryBulbTemperature','HourlyPrecipitation','HourlyPresentWeatherType','HourlyRelativeHumidity','HourlySkyConditions','HourlyVisibility','HourlyWetBulbTemperature','HourlyWindDirection','HourlyWindGustSpeed','HourlyWindSpeed']\n",
    "    existing_columns = [c for c in col if c in df.columns]\n",
    "    df = df[existing_columns]\n",
    "    df_clean = df.dropna(subset=['HourlyPrecipitation'])\n",
    "    \n",
    "  \n",
    "    df_clean.loc[:, 'Timestamp'] = pd.to_datetime(df_clean['DATE'], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "    df_clean = df_clean[df_clean['Timestamp'].dt.month.isin([1, 11, 12])] \n",
    "    return df_clean\n",
    "\n",
    "def process_csv_folder(input_folder, output_folder):\n",
    " \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "          \n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            df = pd.read_csv(file_path,low_memory=False)\n",
    "            \n",
    "     \n",
    "            df_clean = get_weather_from_url(df)\n",
    "            \n",
    "        \n",
    "            output_file_path = os.path.join(output_folder, filename)\n",
    "            df_clean.to_csv(output_file_path, index=False)\n",
    "            print(f\"Processed {filename} and saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "input_folder = r'C:\\Users\\19128\\Desktop\\Mod3\\2023' \n",
    "output_folder = r'C:\\Users\\19128\\Desktop\\2023_1'\n",
    "process_csv_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\3197315761.py:3: DtypeWarning: Columns (11,13,57,78,85,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  flight_data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Quarter',\n",
       " 'Month',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'FlightDate',\n",
       " 'Marketing_Airline_Network',\n",
       " 'Operated_or_Branded_Code_Share_Partners',\n",
       " 'DOT_ID_Marketing_Airline',\n",
       " 'IATA_Code_Marketing_Airline',\n",
       " 'Flight_Number_Marketing_Airline',\n",
       " 'Originally_Scheduled_Code_Share_Airline',\n",
       " 'DOT_ID_Originally_Scheduled_Code_Share_Airline',\n",
       " 'IATA_Code_Originally_Scheduled_Code_Share_Airline',\n",
       " 'Flight_Num_Originally_Scheduled_Code_Share_Airline',\n",
       " 'Operating_Airline ',\n",
       " 'DOT_ID_Operating_Airline',\n",
       " 'IATA_Code_Operating_Airline',\n",
       " 'Tail_Number',\n",
       " 'Flight_Number_Operating_Airline',\n",
       " 'OriginAirportID',\n",
       " 'OriginAirportSeqID',\n",
       " 'OriginCityMarketID',\n",
       " 'Origin',\n",
       " 'OriginCityName',\n",
       " 'OriginState',\n",
       " 'OriginStateFips',\n",
       " 'OriginStateName',\n",
       " 'OriginWac',\n",
       " 'DestAirportID',\n",
       " 'DestAirportSeqID',\n",
       " 'DestCityMarketID',\n",
       " 'Dest',\n",
       " 'DestCityName',\n",
       " 'DestState',\n",
       " 'DestStateFips',\n",
       " 'DestStateName',\n",
       " 'DestWac',\n",
       " 'CRSDepTime',\n",
       " 'DepTime',\n",
       " 'DepDelay',\n",
       " 'DepDelayMinutes',\n",
       " 'DepDel15',\n",
       " 'DepartureDelayGroups',\n",
       " 'DepTimeBlk',\n",
       " 'TaxiOut',\n",
       " 'WheelsOff',\n",
       " 'WheelsOn',\n",
       " 'TaxiIn',\n",
       " 'CRSArrTime',\n",
       " 'ArrTime',\n",
       " 'ArrDelay',\n",
       " 'ArrDelayMinutes',\n",
       " 'ArrDel15',\n",
       " 'ArrivalDelayGroups',\n",
       " 'ArrTimeBlk',\n",
       " 'Cancelled',\n",
       " 'CancellationCode',\n",
       " 'Diverted',\n",
       " 'CRSElapsedTime',\n",
       " 'ActualElapsedTime',\n",
       " 'AirTime',\n",
       " 'Flights',\n",
       " 'Distance',\n",
       " 'DistanceGroup',\n",
       " 'CarrierDelay',\n",
       " 'WeatherDelay',\n",
       " 'NASDelay',\n",
       " 'SecurityDelay',\n",
       " 'LateAircraftDelay',\n",
       " 'FirstDepTime',\n",
       " 'TotalAddGTime',\n",
       " 'LongestAddGTime',\n",
       " 'DivAirportLandings',\n",
       " 'DivReachedDest',\n",
       " 'DivActualElapsedTime',\n",
       " 'DivArrDelay',\n",
       " 'DivDistance',\n",
       " 'Div1Airport',\n",
       " 'Div1AirportID',\n",
       " 'Div1AirportSeqID',\n",
       " 'Div1WheelsOn',\n",
       " 'Div1TotalGTime',\n",
       " 'Div1LongestGTime',\n",
       " 'Div1WheelsOff',\n",
       " 'Div1TailNum',\n",
       " 'Div2Airport',\n",
       " 'Div2AirportID',\n",
       " 'Div2AirportSeqID',\n",
       " 'Div2WheelsOn',\n",
       " 'Div2TotalGTime',\n",
       " 'Div2LongestGTime',\n",
       " 'Div2WheelsOff',\n",
       " 'Div2TailNum',\n",
       " 'Div3Airport',\n",
       " 'Div3AirportID',\n",
       " 'Div3AirportSeqID',\n",
       " 'Div3WheelsOn',\n",
       " 'Div3TotalGTime',\n",
       " 'Div3LongestGTime',\n",
       " 'Div3WheelsOff',\n",
       " 'Div3TailNum',\n",
       " 'Div4Airport',\n",
       " 'Div4AirportID',\n",
       " 'Div4AirportSeqID',\n",
       " 'Div4WheelsOn',\n",
       " 'Div4TotalGTime',\n",
       " 'Div4LongestGTime',\n",
       " 'Div4WheelsOff',\n",
       " 'Div4TailNum',\n",
       " 'Div5Airport',\n",
       " 'Div5AirportID',\n",
       " 'Div5AirportSeqID',\n",
       " 'Div5WheelsOn',\n",
       " 'Div5TotalGTime',\n",
       " 'Div5LongestGTime',\n",
       " 'Div5WheelsOff',\n",
       " 'Div5TailNum',\n",
       " 'Duplicate',\n",
       " 'Unnamed: 119']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read flight data\n",
    "file_path = r'C:\\Users\\19128\\Desktop\\Mod3\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv'\n",
    "flight_data = pd.read_csv(file_path)\n",
    "flight_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    NaN\n",
      "Name: DepDelayMinutes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(flight_data['DepDelayMinutes'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1124\n",
      "1     808\n",
      "2    1846\n",
      "3    1846\n",
      "4    1846\n",
      "Name: CRSDepTime, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selected_columns = ['Year','Quarter','Month','DayofMonth','DayOfWeek','FlightDate','Operating_Airline ',\n",
    "            'Origin','OriginCityName',\n",
    "                    'OriginAirportID',\n",
    "                    'OriginAirportSeqID',\n",
    "                    'OriginCityMarketID',\n",
    "                    'Dest','DestCityName','OriginWac',\n",
    "                    'DestAirportID','CRSDepTime','DepTime','CRSArrTime','ArrTime','Cancelled','CancellationCode','AirTime','Flights','Distance','DistanceGroup','CarrierDelay','WeatherDelay','NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "flight_data=flight_data[selected_columns]\n",
    "print(flight_data['CRSDepTime'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Year, Quarter, Month, DayofMonth, DayOfWeek, FlightDate, Operating_Airline , Origin, OriginCityName, OriginAirportID, OriginAirportSeqID, OriginCityMarketID, Dest, DestCityName, OriginWac, DestAirportID, CRSDepTime, DepTime, CRSArrTime, ArrTime, Cancelled, CancellationCode, AirTime, Flights, Distance, DistanceGroup, CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraftDelay]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(\"NaN values in 'CRSDepTime':\")\n",
    "print(flight_data[flight_data['CRSDepTime'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  AIRPORT_ID  LAT_DEGREES   LATITUDE  LON_DEGREES   LONGITUDE\n",
      "0         184       10135         40.0  40.654722         75.0  -75.438333\n",
      "1         190       10136         32.0  32.409444         99.0  -99.679722\n",
      "2         205       10140         35.0  35.041667        106.0 -106.606389\n",
      "3         210       10141         45.0  45.449722         98.0  -98.421667\n",
      "4         234       10146         31.0  31.532222         84.0  -84.196111\n"
     ]
    }
   ],
   "source": [
    "airport_data=pd.read_csv('filtered_airport.csv')\n",
    "print(airport_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_weather_dir = \"/Users/yaotianyu/Desktop/master/628/mod3/flight_holiday/2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_stations3 = pd.read_csv(\"nearest_stations3.csv\")\n",
    "#weather_station_data = weather_station_data.drop_duplicates(subset=['AirportID', 'StationID'])\n",
    "#print(nearest_stations3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weather_dir=r'C:\\Users\\19128\\Desktop\\Mod3\\2023_1'\n",
    "def generate_corresponding_station_df(stations_df, year, drive_dir):\n",
    "    \"\"\"生成包含 AirportID、最近可用的 StationID 及其排名的 DataFrame\"\"\"\n",
    "  \n",
    "    result = []\n",
    " \n",
    "    unique_airports = stations_df['AirportID'].unique()\n",
    "  \n",
    "    for airport_id in unique_airports:\n",
    "        \n",
    "        candidate_stations = stations_df[stations_df['AirportID'] == airport_id].sort_values(by='Distance')\n",
    "   \n",
    "        found_station = False\n",
    "       \n",
    "        for idx, row in enumerate(candidate_stations.itertuples(), start=1):\n",
    "            station_id = row.StationID\n",
    "            file_path = os.path.join(drive_dir, f\"LCD_{station_id}_{year}.csv\")\n",
    "         \n",
    "            if os.path.exists(file_path):\n",
    "                result.append({\n",
    "                    'AirportID': airport_id,\n",
    "                    'StationID': station_id,\n",
    "                    'No.': idx\n",
    "                })\n",
    "                found_station = True\n",
    "                break  \n",
    "\n",
    "      \n",
    "        if not found_station:\n",
    "            result.append({\n",
    "                'AirportID': airport_id,\n",
    "                'StationID': None,\n",
    "                'No.': None\n",
    "            })\n",
    "\n",
    " \n",
    "    corresponding_station = pd.DataFrame(result)\n",
    "    return corresponding_station\n",
    "\n",
    "corresponding_station = generate_corresponding_station_df(nearest_stations3, 2023, local_weather_dir)\n",
    "year=2023\n",
    "corresponding_station.to_csv(f'corresponding_station_{year}.csv')\n",
    "#f'/Users/yaotianyu/Desktop/master/628/mod3/flight_holiday/climatological_data_{year}'\n",
    "unique_stationid=corresponding_station['StationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "timezone_offsets = {\n",
    "    'EST': -5, 'CST': -6, 'MST': -7, 'PST': -8,\n",
    "    'HST': -10, 'AST': -4, 'AKST': -9, 'HAST': -10,\n",
    "    'ChST': 10, 'SST': -11\n",
    "}\n",
    "\n",
    "def convert_time_to_cst(time, timezone):\n",
    "    \"\"\" 将任意时区的时间转换为 CST \"\"\"\n",
    "    if pd.isna(time) or pd.isna(timezone):\n",
    "        return None\n",
    "    offset_difference = timezone_offsets.get(timezone, 0) - timezone_offsets['CST']\n",
    "    return time + timedelta(hours=-offset_difference)\n",
    "\n",
    "def process_flight_data(flight, timezone):\n",
    "    \"\"\"\n",
    "    处理航班数据，添加起点和终点机场的时区信息，并将时间列转换为 CST。\n",
    "    \"\"\"\n",
    "    for col in ['CRSDepTime', 'DepTime', 'CRSArrTime', 'ArrTime']:\n",
    "        flight[col] = pd.to_datetime(flight[col], errors='coerce')\n",
    "    \n",
    "   \n",
    "    flight = (flight.merge(timezone, left_on=\"OriginAirportID\", right_on=\"AirportID\", how=\"left\")\n",
    "                     .rename(columns={\"Timezone\": \"OriginCityTimezone\"}).drop(columns=[\"AirportID\"]))\n",
    "    flight = (flight.merge(timezone, left_on=\"DestAirportID\", right_on=\"AirportID\", how=\"left\")\n",
    "                     .rename(columns={\"Timezone\": \"DestCityTimezone\"}).drop(columns=[\"AirportID\"]))\n",
    "    \n",
    "   \n",
    "    flight = flight.drop(columns=['StationID_x', 'StationID_y','City_x','City_y'], errors='ignore')\n",
    "    \n",
    " \n",
    "    for col in ['CRSDepTime', 'DepTime']:\n",
    "        flight[f'{col}_CST'] = flight.apply(lambda row: convert_time_to_cst(row[col], row['OriginCityTimezone']), axis=1)\n",
    "    for col in ['CRSArrTime', 'ArrTime']:\n",
    "        flight[f'{col}_CST'] = flight.apply(lambda row: convert_time_to_cst(row[col], row['DestCityTimezone']), axis=1)\n",
    "    \n",
    "    return flight\n",
    "\n",
    "\n",
    "def process_weather_data(weather, timezone):\n",
    "    \"\"\"\n",
    "    处理天气数据，添加时区信息并将日期转换为 CST。\n",
    "    \"\"\"\n",
    "    weather['DATE'] = pd.to_datetime(weather['DATE'])\n",
    "    merged_df = weather.merge(timezone, how='left', left_on='STATION', right_on='StationID')\n",
    "\n",
    "    \n",
    "    merged_df['DATE_CST'] = merged_df.apply(lambda row: convert_time_to_cst(row['DATE'], row['Timezone']), axis=1)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "timezone = pd.read_csv(\"timezone_station_airport_city.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data = flight_data.dropna(subset=['CRSDepTime'])\n",
    "\n",
    "merged_data_origin = pd.merge(\n",
    "    flight_data, \n",
    "    corresponding_station, \n",
    "    left_on='OriginAirportID', \n",
    "    right_on='AirportID', \n",
    "    suffixes=('', '_origin')\n",
    ")\n",
    "merged_data_full = pd.merge(\n",
    "    merged_data_origin, \n",
    "    corresponding_station, \n",
    "    left_on='DestAirportID', \n",
    "    right_on='AirportID', \n",
    "    suffixes=('_origin', '_dest')\n",
    ")\n",
    "columns_to_drop = ['AirportID_origin', 'No._origin', 'AirportID_dest', 'No._dest']\n",
    "merged_data_full = merged_data_full.drop(columns=columns_to_drop)\n",
    "#\n",
    "merged_data_full['CRSDepTime'] = pd.to_datetime(merged_data_full['CRSDepTime'], format='%H%M', errors='coerce')\n",
    "merged_data_full['CRSDepTime'] = merged_data_full['FlightDate'].astype(str) + ' ' + merged_data_full['CRSDepTime'].dt.strftime('%H:%M')\n",
    "merged_data_full['CRSDepTime'] = pd.to_datetime(merged_data_full['CRSDepTime'],errors='coerce')\n",
    "merged_data_full['DepTime'] = pd.to_datetime(merged_data_full['DepTime'], format='%H%M', errors='coerce')\n",
    "merged_data_full['DepTime'] = merged_data_full['FlightDate'].astype(str) + ' ' + merged_data_full['DepTime'].dt.strftime('%H:%M')\n",
    "merged_data_full['DepTime'] = pd.to_datetime(merged_data_full['DepTime'],errors='coerce')\n",
    "merged_data_full['CRSArrTime'] = pd.to_datetime(merged_data_full['CRSArrTime'], format='%H%M', errors='coerce')\n",
    "merged_data_full['CRSArrTime'] = merged_data_full['FlightDate'].astype(str) + ' ' + merged_data_full['CRSArrTime'].dt.strftime('%H:%M')\n",
    "merged_data_full['CRSArrTime'] = pd.to_datetime(merged_data_full['CRSArrTime'],errors='coerce')\n",
    "merged_data_full['ArrTime'] = pd.to_datetime(merged_data_full['ArrTime'], format='%H%M', errors='coerce')\n",
    "merged_data_full['ArrTime'] = merged_data_full['FlightDate'].astype(str) + ' ' + merged_data_full['ArrTime'].dt.strftime('%H:%M')\n",
    "merged_data_full['ArrTime'] = pd.to_datetime(merged_data_full['ArrTime'],errors='coerce')\n",
    "#print(merged_data_full['CRSDepTime_CST'].head())\n",
    "#merged_data_full=merged_data_full.drop_duplicates(subset=['CRSDepTime_CST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_new=process_flight_data(merged_data_full,timezone)\n",
    "\n",
    "#data with weather station id from origin and destination "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10257\n",
    "10599\n",
    "13139\n",
    "13459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_new = merged_data_new[merged_data_new['OriginAirportID'] !=10257 ].reset_index(drop=True)\n",
    "merged_data_new = merged_data_new[merged_data_new['DestAirportID'] !=10257 ].reset_index(drop=True)\n",
    "merged_data_new = merged_data_new[merged_data_new['OriginAirportID'] !=10599 ].reset_index(drop=True)\n",
    "merged_data_new = merged_data_new[merged_data_new['DestAirportID'] !=10599 ].reset_index(drop=True)\n",
    "merged_data_new = merged_data_new[merged_data_new['OriginAirportID'] !=13139 ].reset_index(drop=True)\n",
    "merged_data_new = merged_data_new[merged_data_new['DestAirportID'] !=13139 ].reset_index(drop=True)\n",
    "merged_data_new = merged_data_new[merged_data_new['OriginAirportID'] !=13459 ].reset_index(drop=True)\n",
    "merged_data_new = merged_data_new[merged_data_new['DestAirportID'] !=13459 ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_new=merged_data_new.dropna(subset=['CRSDepTime_CST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate', 'Operating_Airline ', 'Origin', 'OriginCityName', 'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'Dest', 'DestCityName', 'OriginWac', 'DestAirportID', 'CRSDepTime', 'DepTime', 'CRSArrTime', 'ArrTime', 'Cancelled', 'CancellationCode', 'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'StationID_origin', 'StationID_dest', 'OriginCityTimezone', 'DestCityTimezone', 'CRSDepTime_CST', 'DepTime_CST', 'CRSArrTime_CST', 'ArrTime_CST']\n"
     ]
    }
   ],
   "source": [
    "#print(merged_data_new.columns.to_list())\n",
    "pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_weather_dir = \"/Users/yaotianyu/Desktop/master/628/mod3/flight_holiday/2020_1\"\n",
    "local_weather_dir=r'C:\\Users\\19128\\Desktop\\Mod3\\2023_1'\n",
    "weather_data_cache = {}\n",
    "for station_id in unique_stationid:\n",
    "        file_path = f\"{local_weather_dir}/LCD_{station_id}_{2023}.csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            weather_data = pd.read_csv(file_path)\n",
    "            #weather_data['Timestamp'] = pd.to_datetime(weather_data['DATE'], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "            weather_new = process_weather_data(weather_data,timezone)\n",
    "            weather_new['DATE_CST'] = pd.to_datetime(weather_new['DATE_CST'], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "            weather_data_cache[(station_id, 2023)] = weather_new\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate', 'Operating_Airline ', 'Origin', 'OriginCityName', 'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'Dest', 'DestCityName', 'OriginWac', 'DestAirportID', 'CRSDepTime', 'DepTime', 'CRSArrTime', 'ArrTime', 'Cancelled', 'CancellationCode', 'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'StationID_origin', 'StationID_dest', 'OriginCityTimezone', 'DestCityTimezone', 'CRSDepTime_CST', 'DepTime_CST', 'CRSArrTime_CST', 'ArrTime_CST']\n",
      "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Operating_Airline   \\\n",
      "0  2023        4     12          30          6  2023-12-30                 9E   \n",
      "1  2023        4     12          30          6  2023-12-30                 9E   \n",
      "2  2023        4     12           1          5  2023-12-01                 9E   \n",
      "3  2023        4     12           3          7  2023-12-03                 9E   \n",
      "4  2023        4     12           4          1  2023-12-04                 9E   \n",
      "\n",
      "  Origin    OriginCityName  OriginAirportID  ...  SecurityDelay  \\\n",
      "0    IND  Indianapolis, IN            12339  ...            NaN   \n",
      "1    LGA      New York, NY            12953  ...            NaN   \n",
      "2    LGA      New York, NY            12953  ...            NaN   \n",
      "3    LGA      New York, NY            12953  ...            0.0   \n",
      "4    LGA      New York, NY            12953  ...            NaN   \n",
      "\n",
      "   LateAircraftDelay StationID_origin StationID_dest  OriginCityTimezone  \\\n",
      "0                NaN      USW00093819    USW00014732                 EST   \n",
      "1                NaN      USW00014732    USW00093819                 EST   \n",
      "2                NaN      USW00014732    USW00013994                 EST   \n",
      "3               23.0      USW00014732    USW00013994                 EST   \n",
      "4                NaN      USW00014732    USW00013994                 EST   \n",
      "\n",
      "   DestCityTimezone      CRSDepTime_CST         DepTime_CST  \\\n",
      "0               EST 2023-12-30 10:24:00 2023-12-30 10:19:00   \n",
      "1               EST 2023-12-30 07:08:00 2023-12-30 06:59:00   \n",
      "2               CST 2023-12-01 17:46:00 2023-12-01 17:36:00   \n",
      "3               CST 2023-12-03 17:46:00 2023-12-03 18:09:00   \n",
      "4               CST 2023-12-04 17:46:00 2023-12-04 17:39:00   \n",
      "\n",
      "       CRSArrTime_CST         ArrTime_CST  \n",
      "0 2023-12-30 12:28:00 2023-12-30 12:24:00  \n",
      "1 2023-12-30 09:38:00 2023-12-30 08:49:00  \n",
      "2 2023-12-01 20:46:00 2023-12-01 20:31:00  \n",
      "3 2023-12-03 20:46:00 2023-12-03 21:30:00  \n",
      "4 2023-12-04 20:46:00 2023-12-04 20:46:00  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 600456 entries, 0 to 600539\n",
      "Data columns (total 39 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   Year                600456 non-null  int64         \n",
      " 1   Quarter             600456 non-null  int64         \n",
      " 2   Month               600456 non-null  int64         \n",
      " 3   DayofMonth          600456 non-null  int64         \n",
      " 4   DayOfWeek           600456 non-null  int64         \n",
      " 5   FlightDate          600456 non-null  object        \n",
      " 6   Operating_Airline   600456 non-null  object        \n",
      " 7   Origin              600456 non-null  object        \n",
      " 8   OriginCityName      600456 non-null  object        \n",
      " 9   OriginAirportID     600456 non-null  int64         \n",
      " 10  OriginAirportSeqID  600456 non-null  int64         \n",
      " 11  OriginCityMarketID  600456 non-null  int64         \n",
      " 12  Dest                600456 non-null  object        \n",
      " 13  DestCityName        600456 non-null  object        \n",
      " 14  OriginWac           600456 non-null  int64         \n",
      " 15  DestAirportID       600456 non-null  int64         \n",
      " 16  CRSDepTime          600456 non-null  datetime64[ns]\n",
      " 17  DepTime             597691 non-null  datetime64[ns]\n",
      " 18  CRSArrTime          598747 non-null  datetime64[ns]\n",
      " 19  ArrTime             594722 non-null  datetime64[ns]\n",
      " 20  Cancelled           600456 non-null  float64       \n",
      " 21  CancellationCode    2425 non-null    object        \n",
      " 22  AirTime             596783 non-null  float64       \n",
      " 23  Flights             600456 non-null  float64       \n",
      " 24  Distance            600456 non-null  float64       \n",
      " 25  DistanceGroup       600456 non-null  int64         \n",
      " 26  CarrierDelay        93338 non-null   float64       \n",
      " 27  WeatherDelay        93338 non-null   float64       \n",
      " 28  NASDelay            93338 non-null   float64       \n",
      " 29  SecurityDelay       93338 non-null   float64       \n",
      " 30  LateAircraftDelay   93338 non-null   float64       \n",
      " 31  StationID_origin    600456 non-null  object        \n",
      " 32  StationID_dest      600456 non-null  object        \n",
      " 33  OriginCityTimezone  600456 non-null  object        \n",
      " 34  DestCityTimezone    600456 non-null  object        \n",
      " 35  CRSDepTime_CST      600456 non-null  datetime64[ns]\n",
      " 36  DepTime_CST         597691 non-null  datetime64[ns]\n",
      " 37  CRSArrTime_CST      598747 non-null  datetime64[ns]\n",
      " 38  ArrTime_CST         594722 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](8), float64(9), int64(11), object(11)\n",
      "memory usage: 183.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(merged_data_new.columns.to_list())\n",
    "print(merged_data_new.head())\n",
    "print(merged_data_new.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\3751513531.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_result = pd.concat(results, ignore_index=True)\n",
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\3751513531.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_result = pd.concat(results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "#local_weather_dir = \"/Users/yaotianyu/Desktop/master/628/mod3/flight_holiday/2020_1\"\n",
    "for index, row in merged_data_new[500000:].iterrows():\n",
    "    origin_station_id = row['StationID_origin']\n",
    "    dest_station_id = row['StationID_dest']\n",
    "    year = row['Year']\n",
    "    origin_weather_clean = weather_data_cache.get((origin_station_id, year), pd.DataFrame()).dropna(subset=['DATE_CST'])\n",
    "    dest_weather_clean = weather_data_cache.get((dest_station_id, year), pd.DataFrame()).dropna(subset=['DATE_CST'])\n",
    "\n",
    "    single_flight = pd.DataFrame([row])\n",
    "    merged_with_origin = pd.merge_asof(\n",
    "            single_flight.sort_values('CRSDepTime_CST'),\n",
    "            origin_weather_clean.sort_values('DATE_CST'),\n",
    "            left_on='CRSDepTime_CST',\n",
    "            right_on='DATE_CST',\n",
    "            direction='backward',\n",
    "            tolerance=pd.Timedelta('1 hour')\n",
    "        )\n",
    "    \n",
    "    \n",
    "    merged_with_dest = pd.merge_asof(\n",
    "            merged_with_origin.sort_values('CRSDepTime_CST'),\n",
    "            dest_weather_clean.sort_values('DATE_CST'),\n",
    "            left_on='CRSDepTime_CST',\n",
    "            right_on='DATE_CST',\n",
    "            direction='backward',\n",
    "            tolerance=pd.Timedelta('1 hour'),\n",
    "            suffixes=('_originairport', '_destairport')\n",
    "    )\n",
    "    results.append(merged_with_dest)\n",
    "\n",
    "final_result = pd.concat(results, ignore_index=True)\n",
    "\n",
    "final_result.to_csv('demo2023_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\2789665304.py:1: DtypeWarning: Columns (22,53,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d1=pd.read_csv('demo2023_1.csv')\n",
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\2789665304.py:5: DtypeWarning: Columns (53,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d21=pd.read_csv('demo2023_2.csv')\n",
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\2789665304.py:7: DtypeWarning: Columns (49,53,69,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d4=pd.read_csv('demo2023_4.csv')\n",
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\2789665304.py:8: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d5=pd.read_csv('demo2023_5.csv')\n",
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\2789665304.py:9: DtypeWarning: Columns (53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d6=pd.read_csv('demo2023_6.csv')\n"
     ]
    }
   ],
   "source": [
    "d1=pd.read_csv('demo2023_1.csv')\n",
    "#d2=pd.read_csv('demo2022_12.csv')\n",
    "#d23=pd.read_csv('demo2022_13.csv')\n",
    "#d24=pd.read_csv('demo2022_14.csv')\n",
    "d21=pd.read_csv('demo2023_2.csv')\n",
    "d3=pd.read_csv('demo2023_3.csv')\n",
    "d4=pd.read_csv('demo2023_4.csv')\n",
    "d5=pd.read_csv('demo2023_5.csv')\n",
    "d6=pd.read_csv('demo2023_6.csv')\n",
    "#d7=pd.read_csv('demo2023_7.csv')\n",
    "#d8=pd.read_csv('demo2023_8.csv')\n",
    "df1=pd.concat([d1,d21,d3,d4,d5,d6])\n",
    "#df1.to_csv('data_2023_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\3281881384.py:1: DtypeWarning: Columns (23,50,54,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1=pd.read_csv('data_2022_12.csv')\n"
     ]
    }
   ],
   "source": [
    "#df1=pd.read_csv('data_2022_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CRSDepTime'] = pd.to_datetime(df1['CRSDepTime'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df1['CRSDepTime'] = df1['FlightDate'].astype(str) + ' ' + df1['CRSDepTime'].dt.strftime('%H:%M')\n",
    "df1['CRSDepTime'] = pd.to_datetime(df1['CRSDepTime'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19128\\AppData\\Local\\Temp\\ipykernel_46612\\2506966776.py:1: DtypeWarning: Columns (11,13,57,78,85,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  flight_data=pd.read_csv('On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv')\n"
     ]
    }
   ],
   "source": [
    "flight_data=pd.read_csv('On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv')\n",
    "flight_data['CRSDepTime'] = pd.to_datetime(flight_data['CRSDepTime'], format='%H%M', errors='coerce')\n",
    "flight_data['CRSDepTime'] = flight_data['FlightDate'].astype(str) + ' ' + flight_data['CRSDepTime'].dt.strftime('%H:%M')\n",
    "flight_data['CRSDepTime'] = pd.to_datetime(flight_data['CRSDepTime'],errors='coerce')\n",
    "flight_data = flight_data.dropna(subset=['CRSDepTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    274.0\n",
      "1    224.0\n",
      "2    198.0\n",
      "3    193.0\n",
      "4    215.0\n",
      "Name: ActualElapsedTime, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df11 = pd.merge_asof(\n",
    "            df1.sort_values('CRSDepTime'),\n",
    "            flight_data[['CRSDepTime','CRSElapsedTime','DepDelay','ActualElapsedTime','ArrDelay','DepTimeBlk','ArrTimeBlk']].sort_values('CRSDepTime'),\n",
    "            left_on='CRSDepTime',\n",
    "            right_on='CRSDepTime',\n",
    "            direction='backward',\n",
    "    )\n",
    "print(df11['ActualElapsedTime'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11.to_csv('data202312.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
